{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-07-13T07:56:56.028590Z",
     "start_time": "2025-07-13T07:56:56.024737Z"
    }
   },
   "source": [
    "import torch\n",
    "torch.manual_seed(123);"
   ],
   "outputs": [],
   "execution_count": 73
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T07:56:56.049533Z",
     "start_time": "2025-07-13T07:56:56.041685Z"
    }
   },
   "cell_type": "code",
   "source": [
    "torch.manual_seed(123)\n",
    "idx = torch.tensor([2,3,1]) # 3 Training examples, where each index corresponds to the character\n",
    "\n",
    "number_idx = max(idx)+1  # input dimension of a one-hot encoded vector is the number of indices (the highest index +1)\n",
    "output_dim = 5\n",
    "\n",
    "embedd = torch.nn.Embedding(number_idx, output_dim)\n",
    "print(embedd(idx))"
   ],
   "id": "a83c54e3bba2325b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.6957, -1.8061, -1.1589,  0.3255, -0.6315],\n",
      "        [-2.8400, -0.7849, -1.4096, -0.4076,  0.7953],\n",
      "        [ 1.3010,  1.2753, -0.2010, -0.1606, -0.4015]],\n",
      "       grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "execution_count": 74
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T08:06:11.693301Z",
     "start_time": "2025-07-13T08:06:11.684192Z"
    }
   },
   "cell_type": "code",
   "source": "embedd.weight.T.detach()",
   "id": "333832e3cc1acd95",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.3374,  1.3010,  0.6957, -2.8400],\n",
       "        [-0.1778,  1.2753, -1.8061, -0.7849],\n",
       "        [-0.3035, -0.2010, -1.1589, -1.4096],\n",
       "        [-0.5880, -0.1606,  0.3255, -0.4076],\n",
       "        [ 1.5810, -0.4015, -0.6315,  0.7953]])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 81
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T08:07:00.243122Z",
     "start_time": "2025-07-13T08:07:00.232987Z"
    }
   },
   "cell_type": "code",
   "source": "linear.weight.detach()",
   "id": "ecb548d75babc9ce",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.3374,  1.3010,  0.6957, -2.8400],\n",
       "        [-0.1778,  1.2753, -1.8061, -0.7849],\n",
       "        [-0.3035, -0.2010, -1.1589, -1.4096],\n",
       "        [-0.5880, -0.1606,  0.3255, -0.4076],\n",
       "        [ 1.5810, -0.4015, -0.6315,  0.7953]])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 82
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T08:05:59.552718Z",
     "start_time": "2025-07-13T08:05:59.544595Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# using torch.nn.Linear\n",
    "\n",
    "torch.manual_seed(123)\n",
    "idx = torch.tensor([2,3,1])\n",
    "onehot = torch.nn.functional.one_hot(idx)\n",
    "linear = torch.nn.Linear(number_idx, output_dim, bias=False)\n",
    "print(onehot)\n",
    "linear.weight = torch.nn.Parameter(embedd.weight.T.detach())\n",
    "print(linear(onehot.float()))"
   ],
   "id": "e92358097e450f4e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 0, 1, 0],\n",
      "        [0, 0, 0, 1],\n",
      "        [0, 1, 0, 0]])\n",
      "tensor([[ 0.6957, -1.8061, -1.1589,  0.3255, -0.6315],\n",
      "        [-2.8400, -0.7849, -1.4096, -0.4076,  0.7953],\n",
      "        [ 1.3010,  1.2753, -0.2010, -0.1606, -0.4015]], grad_fn=<MmBackward0>)\n"
     ]
    }
   ],
   "execution_count": 80
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T07:56:56.128534Z",
     "start_time": "2025-07-13T07:56:56.123112Z"
    }
   },
   "cell_type": "code",
   "source": "print(linear(onehot.float()))",
   "id": "fe6aab4fbb9357fc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.2483, -0.3634, -0.1847, -0.1836, -0.1179],\n",
      "        [ 0.1886, -0.3975,  0.1871, -0.0983,  0.1605],\n",
      "        [ 0.0166,  0.3665,  0.2264, -0.3034,  0.3274]], grad_fn=<MmBackward0>)\n"
     ]
    }
   ],
   "execution_count": 76
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T07:56:56.144292Z",
     "start_time": "2025-07-13T07:56:56.141578Z"
    }
   },
   "cell_type": "code",
   "source": "import re",
   "id": "d41a556f0340cdc",
   "outputs": [],
   "execution_count": 77
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T07:56:56.185593Z",
     "start_time": "2025-07-13T07:56:56.180166Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tt = \"this is a test to tokenize dont's\"\n",
    "\n",
    "def tokenize(text):\n",
    "    return [r.lower() for r in re.findall(\"\\w+\", text)]\n",
    "\n",
    "tokenize(tt)"
   ],
   "id": "b29c2806affb3aaa",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['this', 'is', 'a', 'test', 'to', 'tokenize', 'dont', 's']"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 78
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T07:56:56.201129Z",
     "start_time": "2025-07-13T07:56:56.198540Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "d1be46dfc092d780",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
