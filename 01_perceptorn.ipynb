{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "%load_ext watermark\n",
    "%watermark -v -p numpy,pandas,matplotlib\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Generate linearly separable data points\n",
    "np.random.seed(42)\n",
    "n_samples = 100\n",
    "\n",
    "# Generate two clusters\n",
    "cluster1_x = np.random.normal(2, 1, (n_samples // 2, 2))\n",
    "cluster2_x = np.random.normal(-2, 1, (n_samples // 2, 2))\n",
    "\n",
    "# Combine clusters and create labels\n",
    "X = np.vstack([cluster1_x, cluster2_x])\n",
    "y = np.hstack([np.ones(n_samples // 2), np.zeros(n_samples // 2)])\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(X, columns=['x1', 'x2'])\n",
    "df['label'] = y\n",
    "\n",
    "df\n"
   ],
   "id": "20dda1a3ec9ed805",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "##-- create data with drawing\n",
    "\n",
    "from drawdata import ScatterWidget\n",
    "widget = ScatterWidget()\n",
    "widget"
   ],
   "id": "f305ef0a74fd1d55",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "# df.to_csv('./assets/linearly_separable_data.csv', index=False)",
   "id": "f77bb4c1195895aa",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df = widget.data_as_pandas\n",
    "# df = pd.read_csv('./assets/linearly_separable_data.csv')\n",
    "df['label'] = df['batch']\n",
    "df.rename(columns={'x': 'x1','y':'x2'}, inplace=True)"
   ],
   "id": "66b6f4fbef647583",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "5d2d541523f74e6b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "X_train = df[['x1', 'x2']].values\n",
    "y_train = df['label'].values"
   ],
   "id": "78e2565cfb6ba68a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "X_train.shape, y_train.shape",
   "id": "62dc9e163d8cca3c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "np.bincount(y_train)"
   ],
   "id": "a7a6186e7f0a1c6b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(\n",
    "    X_train[y_train==0,0], X_train[y_train==0,1], 'D', color='blue', label='class 0'\n",
    ")\n",
    "plt.plot(\n",
    "    X_train[y_train==1,0], X_train[y_train==1,1], '^', color='red', label='class 1'\n",
    ")\n",
    "plt.legend(loc='upper left')\n",
    "plt.grid()\n",
    "plt.show()"
   ],
   "id": "9931d97b8d392e4b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class Perceptron:\n",
    "    def __init__(self, num_features):\n",
    "        self.weights = [0.0 for _ in range(num_features)]\n",
    "        # self.weights = np.zeros(num_features)\n",
    "        self.bias = 0.0\n",
    "\n",
    "ppn = Perceptron(num_features=2)"
   ],
   "id": "6642e92405fd1db",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "ppn.weights",
   "id": "73ecbda5189a3fff",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Let's write the mathematical formula for calculating Z (net input) in a perceptron:\n",
    "\n",
    "Z = x₁w₁ + x₂w₂ + b\n",
    "\n",
    "where:\n",
    "- x₁, x₂ are input features \n",
    "- w₁, w₂ are weights\n",
    "- b is bias term"
   ],
   "id": "9fbaf4a38de190df"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class Perceptron:\n",
    "    def __init__(self, num_features):\n",
    "        self.weights = [0.0 for _ in range(num_features)]\n",
    "        # self.weights = np.zeros(num_features)\n",
    "        self.bias = 0.0\n",
    "\n",
    "    def forward(self, x):\n",
    "        weighted_sum_z = self.bias\n",
    "        for i, _ in enumerate(self.weights):\n",
    "            weighted_sum_z += self.weights[i] * x[i]\n",
    "\n",
    "        if weighted_sum_z > 0:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "ppn = Perceptron(num_features=2)\n",
    "\n",
    "x = [1.1, 2.1]\n",
    "ppn.forward(x)"
   ],
   "id": "224e26718496bf0f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# update method\n",
    "\n",
    "\n",
    "class Perceptron:\n",
    "    def __init__(self, num_features):\n",
    "        self.num_features = num_features\n",
    "        self.weights = [0.0 for _ in range(num_features)]\n",
    "        # self.weights = np.zeros(num_features)\n",
    "        self.bias = 0.0\n",
    "\n",
    "    def forward(self, x):\n",
    "        weighted_sum_z = self.bias\n",
    "        for i, _ in enumerate(self.weights):\n",
    "            weighted_sum_z += self.weights[i] * x[i]\n",
    "        if weighted_sum_z > 0.0:\n",
    "            prediction = 1\n",
    "        else:\n",
    "            prediction = 0\n",
    "        return prediction\n",
    "\n",
    "    def update(self, x, true_y):\n",
    "        prediction = self.forward(x)\n",
    "        error = true_y - prediction\n",
    "\n",
    "        #update\n",
    "        self.bias += error\n",
    "        for i, _ in enumerate(self.weights):\n",
    "            self.weights[i] += x[i] * error\n",
    "\n",
    "        return error\n",
    "\n",
    "ppn = Perceptron(num_features=2)\n",
    "x = [1.1, 2.1]\n",
    "ppn.update(x, true_y=1)\n"
   ],
   "id": "4f6e6e7d39b9a615",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(\"Model Parameters:\")\n",
    "print(ppn.weights)\n",
    "print(ppn.bias)"
   ],
   "id": "ca52ebf6d1651a22",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def trainmodel(model, all_x, all_y, epochs=10):\n",
    "    for epoch in range(epochs):\n",
    "        error_count = 0\n",
    "        for x, y in zip(all_x, all_y):\n",
    "            error = model.update(x, y)\n",
    "            error_count += abs(error)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}: Error Count = {error_count}\")"
   ],
   "id": "8fb5af6866c2050e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "ppn = Perceptron(num_features=2)\n",
    "\n",
    "trainmodel(ppn, X_train, y_train, epochs=5)"
   ],
   "id": "9fcb2dc0083cc2f0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Standardize the data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# Check the standardized data\n",
    "print(\"Original data range:\")\n",
    "print(f\"X1: [{X_train[:, 0].min():.2f}, {X_train[:, 0].max():.2f}]\")\n",
    "print(f\"X2: [{X_train[:, 1].min():.2f}, {X_train[:, 1].max():.2f}]\")\n",
    "\n",
    "print(\"\\nStandardized data range:\")\n",
    "print(f\"X1: [{X_train_scaled[:, 0].min():.2f}, {X_train_scaled[:, 0].max():.2f}]\")\n",
    "print(f\"X2: [{X_train_scaled[:, 1].min():.2f}, {X_train_scaled[:, 1].max():.2f}]\")\n",
    "\n",
    "print(\"\\nStandardized data mean and std:\")\n",
    "print(f\"Mean: {X_train_scaled.mean(axis=0)}\")\n",
    "print(f\"Std: {X_train_scaled.std(axis=0)}\")\n",
    "\n",
    "# Visualize standardized data\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(X_train[y_train == 0, 0], X_train[y_train == 0, 1], 'D', color='blue', label='class 0')\n",
    "plt.plot(X_train[y_train == 1, 0], X_train[y_train == 1, 1], '^', color='red', label='class 1')\n",
    "plt.title('Original Data')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(X_train_scaled[y_train == 0, 0], X_train_scaled[y_train == 0, 1], 'D', color='blue', label='class 0')\n",
    "plt.plot(X_train_scaled[y_train == 1, 0], X_train_scaled[y_train == 1, 1], '^', color='red', label='class 1')\n",
    "plt.title('Standardized Data')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Now train with standardized data\n",
    "ppn_scaled = Perceptron(num_features=2)\n",
    "trainmodel(ppn_scaled, X_train_scaled, y_train, epochs=5)"
   ],
   "id": "91030828a60e4ac0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Evaluate the resul",
   "id": "5ac412fc167a8955"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "ppn_scaled = Perceptron(num_features=2)\n",
    "trainmodel(ppn_scaled, X_train_scaled, y_train, epochs=5)\n"
   ],
   "id": "57118145158d1e6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "b37142e519ee0ff6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def evaluate(model: Perceptron, all_x, all_y):\n",
    "\n",
    "    correct = 0\n",
    "    for x,y in zip(all_x, all_y):\n",
    "        prediction = model.forward(x)\n",
    "        correct += int(prediction == y)\n",
    "\n",
    "    return correct / len(all_y)\n",
    "\n",
    "train_accuracy = evaluate(ppn_scaled, scaler.fit_transform(X_train), y_train)\n",
    "print(f\"Training Accuracy: {train_accuracy*100:.2f}%\")\n",
    "\n",
    "\n",
    "\n"
   ],
   "id": "b993f4c89feb6d88",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# look at deciasion boundary\n",
    "\n",
    "def plot_decision_boundary(model:Perceptron):\n",
    "\n",
    "    w1, w2 = model.weights\n",
    "    b = model.bias\n",
    "\n",
    "    x1_min = -20\n",
    "    x2_min = (-(w1 * x1_min) - b) / w2\n",
    "\n",
    "    x1_max = 20\n",
    "    x2_max = (-(w1 * x1_max) - b) / w2\n",
    "\n",
    "    return x1_min, x2_min, x1_max, x2_max\n",
    "\n"
   ],
   "id": "e856f7ffbe0611b3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "x1_min, x2_min, x1_max, x2_max = plot_decision_boundary(ppn_scaled)\n",
    "\n",
    "plt.plot(X_train_scaled[y_train == 0, 0], X_train_scaled[y_train == 0, 1], 'D', color='blue', label='class 0')\n",
    "plt.plot(X_train_scaled[y_train == 1, 0], X_train_scaled[y_train == 1, 1], '^', color='red', label='class 1')\n",
    "\n",
    "plt.plot([x1_min, x1_max], [x2_min, x2_max],  color='k')\n",
    "plt.title('Decision Boundary')\n",
    "plt.xlim([-5, 5])\n",
    "plt.ylim([-5, 5])\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ],
   "id": "25d91c89b61ec20f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Exercise\n",
    "\n",
    "# Add early stopping\n",
    "\n",
    "\n",
    "def trainmodel(model, all_x, all_y, epochs=10):\n",
    "    for epoch in range(epochs):\n",
    "        error_count = 0\n",
    "        for x, y in zip(all_x, all_y):\n",
    "            error = model.update(x, y)\n",
    "            error_count += abs(error)\n",
    "\n",
    "        # break epoch run if error is 0\n",
    "        print(f\"Epoch {epoch+1}: Error Count = {error_count}\")\n",
    "        if error_count == 0:\n",
    "            break\n",
    "\n"
   ],
   "id": "abab527e2da439fe",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Exercise 2: Initialize the model parameters with small random numbers instead of 0’s\n",
    "# Modify the Perceptron class in Section 4 such that it initializes the weights and bias unit using small random numbers (detailed instructions are provided in the notebook). Then observe how it affects the training performance of the perceptron. Does it train/learn better or worse?\n",
    "\n",
    "import random\n",
    "class Perceptron:\n",
    "    def __init__(self, num_features):\n",
    "        # random.seed(124)\n",
    "        self.num_features = num_features\n",
    "        self.weights = [random.uniform(-0.5, 0.5) for _ in range(num_features)]\n",
    "        # self.weights = [0.0 for _ in range(num_features)]\n",
    "        # self.weights = np.zeros(num_features)\n",
    "        self.bias = random.uniform(-0.5, 0.5)\n",
    "        # self.bias = 0.0\n",
    "\n",
    "    def forward(self, x):\n",
    "        weighted_sum_z = self.bias\n",
    "        for i, _ in enumerate(self.weights):\n",
    "            weighted_sum_z += self.weights[i] * x[i]\n",
    "        if weighted_sum_z > 0.0:\n",
    "            prediction = 1\n",
    "        else:\n",
    "            prediction = 0\n",
    "        return prediction\n",
    "\n",
    "    def update(self, x, true_y):\n",
    "        prediction = self.forward(x)\n",
    "        error = true_y - prediction\n",
    "\n",
    "        #update\n",
    "        self.bias += error\n",
    "        for i, _ in enumerate(self.weights):\n",
    "            self.weights[i] += x[i] * error\n",
    "\n",
    "        return error\n"
   ],
   "id": "e5d949d8bce600d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "ppn_scaled = Perceptron(num_features=2)\n",
    "trainmodel(ppn_scaled, X_train_scaled, y_train, epochs=5)\n",
    "\n",
    "train_accuracy = evaluate(ppn_scaled, scaler.fit_transform(X_train), y_train)\n",
    "print(f\"Training Accuracy: {train_accuracy*100:.2f}%\")\n",
    "\n",
    "x1_min, x2_min, x1_max, x2_max = plot_decision_boundary(ppn_scaled)\n",
    "\n",
    "plt.plot(X_train_scaled[y_train == 0, 0], X_train_scaled[y_train == 0, 1], 'D', color='blue', label='class 0')\n",
    "plt.plot(X_train_scaled[y_train == 1, 0], X_train_scaled[y_train == 1, 1], '^', color='red', label='class 1')\n",
    "\n",
    "plt.plot([x1_min, x1_max], [x2_min, x2_max],  color='k')\n",
    "plt.title('Decision Boundary')\n",
    "plt.xlim([-5, 5])\n",
    "plt.ylim([-5, 5])\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ],
   "id": "f8880d30981f5405",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Exercise 3: Use a learning rate for updating the weights and bias unit\n",
    "# Modify the Perceptron class using a so-called learning rate for updating the weights and bias unit. The learning rate is a setting for adjusting the magnitude of the weight and bias unit updates. Changing the learning rate can accelerate or slow down the learning speed of the perceptron (in terms of the number of iterations required for finding a good decision boundary).\n",
    "#\n",
    "\n",
    "data = {\n",
    "    'x1': [0.77, -0.33, 0.91, -0.37, -0.63, 0.39, -0.49, -0.68, -0.10, -0.05,\n",
    "           3.88, 0.73, 0.83, 1.59, 1.14, 1.73, 1.31, 1.56, 1.23, 1.33],\n",
    "    'x2': [-1.14, 1.44, -3.07, -1.91, -1.53, -1.99, -2.74, -1.52, -3.43, -1.95,\n",
    "           0.65, 2.97, 3.94, 1.25, 3.91, 2.80, 1.85, 3.85, 2.54, 2.03],\n",
    "    'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "              1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "# print(df)\n",
    "\n",
    "\n",
    "X_train = df[['x1', 'x2']].values\n",
    "y_train = df['label'].values\n",
    "\n",
    "class Perceptron:\n",
    "    def __init__(self, num_features, learning_rate=1):\n",
    "        random.seed(123)\n",
    "        self.learning_rate = learning_rate\n",
    "        self.num_features = num_features\n",
    "        self.weights = [random.uniform(-0.5, 0.5) for _ in range(num_features)]\n",
    "        # self.weights = [0.0 for _ in range(num_features)]\n",
    "        # self.weights = np.zeros(num_features)\n",
    "        self.bias = random.uniform(-0.5, 0.5)\n",
    "        # self.bias = 0.0\n",
    "\n",
    "    def forward(self, x):\n",
    "        weighted_sum_z = self.bias\n",
    "        for i, _ in enumerate(self.weights):\n",
    "            weighted_sum_z += self.weights[i] * x[i]\n",
    "        if weighted_sum_z > 0.0:\n",
    "            prediction = 1\n",
    "        else:\n",
    "            prediction = 0\n",
    "        return prediction\n",
    "\n",
    "    def update(self, x, true_y):\n",
    "        prediction = self.forward(x)\n",
    "        error = true_y - prediction\n",
    "\n",
    "        #update\n",
    "        self.bias += error * self.learning_rate\n",
    "        for i, _ in enumerate(self.weights):\n",
    "            self.weights[i] += (x[i] * error) * self.learning_rate\n",
    "\n",
    "        return error\n",
    "\n",
    "def trainmodel(model, all_x, all_y, epochs=10):\n",
    "    for epoch in range(epochs):\n",
    "        error_count = 0\n",
    "        for x, y in zip(all_x, all_y):\n",
    "            error = model.update(x, y)\n",
    "            error_count += abs(error)\n",
    "\n",
    "        # break epoch run if error is 0\n",
    "        print(f\"Epoch {epoch+1}: Error Count = {error_count}\")\n",
    "        # if error_count == 0:\n",
    "        #     break\n"
   ],
   "id": "878d0d363667e5e9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "ppn = Perceptron(num_features=2, learning_rate=0.5)\n",
    "trainmodel(ppn, X_train, y_train, epochs=5)\n",
    "\n",
    "train_accuracy = evaluate(ppn,X_train, y_train)\n",
    "print(f\"Training Accuracy: {train_accuracy*100:.2f}%\")\n",
    "\n",
    "x1_min, x2_min, x1_max, x2_max = plot_decision_boundary(ppn)\n",
    "\n",
    "plt.plot(\n",
    "    X_train[y_train == 0, 0],\n",
    "    X_train[y_train == 0, 1],\n",
    "    marker=\"D\",\n",
    "    markersize=10,\n",
    "    linestyle=\"\",\n",
    "    label=\"Class 0\",\n",
    ")\n",
    "\n",
    "plt.plot(\n",
    "    X_train[y_train == 1, 0],\n",
    "    X_train[y_train == 1, 1],\n",
    "    marker=\"^\",\n",
    "    markersize=13,\n",
    "    linestyle=\"\",\n",
    "    label=\"Class 1\",\n",
    ")\n",
    "\n",
    "plt.plot([x1_min, x1_max], [x2_min, x2_max], color=\"k\")\n",
    "\n",
    "plt.legend(loc=2)\n",
    "\n",
    "plt.xlim([-5, 5])\n",
    "plt.ylim([-5, 5])\n",
    "\n",
    "plt.xlabel(\"Feature $x_1$\", fontsize=12)\n",
    "plt.ylabel(\"Feature $x_2$\", fontsize=12)\n",
    "\n",
    "plt.grid()\n",
    "plt.show()\n"
   ],
   "id": "ed98e83d4baf2e96",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "32b9007db30c24cd"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
